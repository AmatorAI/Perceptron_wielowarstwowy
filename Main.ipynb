{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron wielowarstwowy - prosta sieć neuronowa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Celem projektu będzie zbudowanie prostej sieci neuronowej za pomocą biblioteki SKLEARN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/nn.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jeśli chodzi o dane, posłużę się również wbudowanym zbiorem danych LOAD_DIGITS. Dane te przedstawiają \"ręcznie\" napisane cyfry od 0 do 9. Jedna obserwacja to jeden obrazek. Jeden obrazek to 8x8 pixeli, czy 64 pixeli posiada jeden obrazek. Mamy zmienne, które reprezentują wartośc nasycenia czerni w poszczeólnym pixelu. Czyli każda zmienna mówi nam w jakim stopniu zaczerniony jest pixel (biały, czarny czy skala szarości)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zanim jednak przedstawie przykładowe liczby, zaimportuje potrzebne biblioteki no i oczywiście dane.\n",
    "Dodatkowo podzielę sobie już dane na obserwacje i zmiennie (data, target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_digits()\n",
    "X = dataset.data\n",
    "y= dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "for index, (image, label) in enumerate(zip(dataset.data[0:10], dataset.target[0:10])):\n",
    "    plt.subplot(1, 10, index+1)\n",
    "    plt.imshow(np.reshape(image, (8,8)), cmap=plt.cm.gray)\n",
    "    plt.title(label, fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzę ile mamy obserwacji i zmiennych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dodatkowo przed zbudowaniem perceptronu wielowarstwowego, podzielę dane na zbiór treningowy i testowy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Budowanie sieci neuronowej (perceptron wielowarstwowy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "#?MLPClassifier\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dane zamykają się w przedziale od 0 do 16, gdzie 0 to biały a 16 to czarny to co po środku to skala szarości. Pytanie brzmi czy powinnismy zestandaryzować i zeskalowac dane ? Ogólnie prawie zawsze powinniśmy to robić, żeby dane było w okolicy 0.\n",
    "\n",
    "Możemy zrobić to np. tak że podzielimy nasze wartości w danej kolumnie przez największą wartość tej kolumny (NIE ZAWSZE, ZALEŻY OD DANYCH) \n",
    "\n",
    "Najczęściej robimy tak, że np. przy obrazach gdzie wartości są dodatnie i odpowiadają jakiemuś nasyceniu kolorów, i są to wartości 0+ ,a jeśli wartości są np. ujemne to można podzielić przez maksimum z wartości bezwzględnej i wtedy się przeskaluję do przedziału (-1) - (+1)\n",
    "\n",
    "Albo za pomocą StandardScalera - ma taką wadę że jeżeli odchylenie standardowe jest bardzo małe to istnieje ryzyko, że po podzieleniu warości będą bardzo duże\n",
    "\n",
    "Albo za pomocą MaxAbsSclaer - czyli to jest dokładnie dzielenie przez wartość bezwzględną największą w kolumnie (jest to s'kalernowy transformator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utworzę teraz dwu warstwową sieć neuronową, gdzie w pierwszej warstwie będą 32 neurony a w drugiej 16. (MLPClassifier((32,16)).\n",
    "Dodatkowo użyję MaxAbsScaler() w celu zeskalowania danych. Dla tak małych i prostych danych nie powinno to mieć dużego znaczenia, ale warto to zrobić.\n",
    "\n",
    "Wszystkie powyższe czynności zamknę w pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(MaxAbsScaler(), MLPClassifier((32,16)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniższy błąd mówi o przekroczeniu domyślnej liczby epoko (200) podczas uczenia.\n",
    "Zmienię ten parametr w kolejnym modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programowanie\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('maxabsscaler', MaxAbsScaler()),\n",
       "                ('mlpclassifier', MLPClassifier(hidden_layer_sizes=(32, 16)))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdzam skuteczność mojego modelu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9574074074074074"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mój model jest skuteczny w około 95%, całkiem nieźle.\n",
    "Za każdym uruchomieniem uczenia się, model będzie miał delikatnie inną skuteczność."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teraz zbuduję kolejną sieć neuronową z tym, że skupię się na kilku parametrach i hiperparametrach tej sieci.\n",
    "#### Dodatkowo dodam dwie warstwy ukryte w mojej sieci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = make_pipeline(MaxAbsScaler(), MLPClassifier((64, 32, 16, 8), \n",
    "                                                    activation='tanh',\n",
    "                                                    solver='sgd',\n",
    "                                                    batch_size=10,\n",
    "                                                    max_iter=500,\n",
    "                                                    shuffle=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opis wybranych przeze mnie parametrów i hipermarametrów :\n",
    "##### Hiperparametry:\n",
    "* hidden_layer_size - wielkości warst ukrytych, w naszym przypadku (64, 32, 16, 8)\n",
    "* activation - funcja aktywacji (jedna wspólna dla wszystkich neuronów), do wyboru mamy:\n",
    "##### identity - neuron zwraca sumę bezpośrednio \n",
    "##### logistic - to samo co sigmoid zwraca wartości z przedziało 0-1, \n",
    "##### tanh - tangens hiperboliczny bardzo podobny do funkcji sigmoid z tym że jest rozciągnięty z przedziału 0-1 do (-1) - (1)\n",
    "##### relu - relu ta funkcjia nie jest ogrniaczona \n",
    "\n",
    "(Używa się akurat tych funkcji, ponieważ DZIAŁAJĄ :) i łatwo liczy się dla nich pochodne.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parametry/argumenty:\n",
    "* solver - algortym uczenia \n",
    "##### lbfgs - klasyczny algortym, rzadko używany\n",
    "##### sgd - liczymy na próbkach, aktualizujemy metodą spadku gradientu\n",
    "##### adam -  podobny do  SGD, tylko wzór w metodzie spadku gradientu jest trochę zmodyfikowany (zmodyfikowane SGD)\n",
    "\n",
    "\n",
    "* batch_size - wielkość porcji pojedyńczej obserwacji tzw. BACZ, ma większe znaczenie przy większej ilości danych\n",
    "* max_iter - liczba epok przez którą, chcemy uczyć sieć (mogą uczyć się kilka epok, a czasami kilkaset, średnio kilkadziesiąt)\n",
    "* shuffle - przemieszać obserwacje przed uczeniem czy nie. Ogólnie dane powinny być przemieszane, ponieważ kolejność obserwacji może wpłynać na proces uczenia (parametr domyslnie ustawiony jest na TRUE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jest oczywiście o wiele więcej argumentów dla perceptronu wielowarstwowego, ale mają znaczenie przy większej ilości danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('maxabsscaler', MaxAbsScaler()),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(activation='tanh', batch_size=10,\n",
       "                               hidden_layer_sizes=(64, 32, 16, 8), max_iter=500,\n",
       "                               solver='sgd'))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skuteczność modelu troche się poprawiła, jednak przy kolejnym uruchomieniu wynik ten ulegnie zmianie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9629629629629629"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, model1.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Sprawdzę jeszcze jak zachowują się moje modele (model, model1) z różnymi ilościami neuronów przy jednej warstwie ukrytej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :  0.37592592592592594\n",
      "5 :  0.9092592592592592\n",
      "10 :  0.9648148148148148\n",
      "15 :  0.9703703703703703\n",
      "20 :  0.9629629629629629\n",
      "25 :  0.9703703703703703\n",
      "50 :  0.9722222222222222\n",
      "100 :  0.9740740740740741\n",
      "200 :  0.9796296296296296\n",
      "500 :  0.975925925925926\n",
      "1000 :  0.9777777777777777\n",
      "10000 :  0.975925925925926\n"
     ]
    }
   ],
   "source": [
    "for hlz in [1, 5, 10 , 15, 20, 25, 50, 100, 200, 500, 1000, 10000]:\n",
    "    model = make_pipeline(MaxAbsScaler(), MLPClassifier((hlz), max_iter=100000)) #zmieniłem ilość epok, aby uniknać błędów\n",
    "    model.fit(X_train, y_train)\n",
    "    print(hlz,': ',accuracy_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widzimy, że za każdym razem gdy uczymy sieć, wynik jest trochę inny ALE podobny. Nauczona sieć nie powinna dawać skranie różnych wyników ponieważ będzie mówiło to o tym że, sieć jest niestabilna i powinniśmy popracować nad stabilnością sieci."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :  0.24814814814814815\n",
      "5 :  0.9148148148148149\n",
      "10 :  0.9388888888888889\n",
      "15 :  0.9537037037037037\n",
      "20 :  0.9537037037037037\n",
      "25 :  0.9481481481481482\n",
      "50 :  0.9462962962962963\n",
      "100 :  0.9425925925925925\n",
      "200 :  0.95\n",
      "500 :  0.9518518518518518\n",
      "1000 :  0.9518518518518518\n",
      "10000 :  0.9481481481481482\n"
     ]
    }
   ],
   "source": [
    "for hlz in [1, 5, 10 , 15, 20, 25, 50, 100, 200, 500, 1000, 10000]:\n",
    "    model1 = make_pipeline(MaxAbsScaler(), MLPClassifier((hlz), \n",
    "                                                    activation='tanh',\n",
    "                                                    solver='sgd',\n",
    "                                                    batch_size='auto',\n",
    "                                                    max_iter=100000,\n",
    "                                                    shuffle=True))\n",
    "    model1.fit(X_train, y_train)\n",
    "    print(hlz,': ',accuracy_score(y_test, model1.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porównując dwa powyższe modele można zauważyć, że 'model' jest lepszy od 'model1'. \n",
    "Pierwszy model zdobył skuteczność na poziomie 97% przy 15 neuronach. Przy wyższych ilościach neuronów ta skuteczność jest minimalnie lepsza, ale muszę wybrać pomiędzy skutecznością, a szybkością uczenia się.\n",
    "\n",
    "Drugi model zdobył 'jedynie' 95% skuteczności, dodatkowo duża liczba neuronów powoduje prawdopodobnie przeuczenie się modelu.\n",
    "\n",
    "Wniosek jest prosty - POTĘGA TKWI W PROSTOCIE :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
